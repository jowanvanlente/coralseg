{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Export to COCO\n",
    "\n",
    "For large datasets (5000+ images) → Roboflow upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "  Method: graph\n",
      "  Scale: 0.2 (20%)\n",
      "  Region merging: ON\n",
      "  Confidence filtering: OFF\n",
      "  Min annotations: 90\n",
      "  Require spread: True\n",
      "  Recursive: True\n",
      "  Target usage: 80% (adaptive workers)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these settings\n",
    "# =============================================================================\n",
    "\n",
    "# --- Paths ---\n",
    "# Default paths use sample_data/ included in the repo so the notebook\n",
    "# works immediately after cloning.  Replace with your own data paths.\n",
    "PATH_IMAGES = 'sample_data'\n",
    "PATH_ANNOTATIONS = 'sample_data/sample_annotations.csv'\n",
    "PATH_LABELSET = 'labelset.json'\n",
    "PATH_OUTPUT = 'output/coco_export.json'\n",
    "\n",
    "# --- Image Search ---\n",
    "RECURSIVE_SEARCH = True  # Search subfolders for images\n",
    "\n",
    "# --- Segmentation Method ---\n",
    "# Options: 'superpixel', 'adaptive', 'graph', 'hybrid', 'graph_first'\n",
    "SEGMENTATION_METHOD = 'graph'\n",
    "\n",
    "# --- Processing Scale ---\n",
    "# Lower = faster but less detail (0.25 = 25% of original size)\n",
    "SCALE_FACTOR = 0.2\n",
    "\n",
    "# --- Superpixel Parameters (SLIC) ---\n",
    "SUPERPIXEL_SCALES = [3000, 900, 30]\n",
    "\n",
    "# --- Adaptive Parameters ---\n",
    "ADAPTIVE_SCALES = [1.0, 0.5, 0.25]\n",
    "ADAPTIVE_MIN_DISTANCE = 10\n",
    "ADAPTIVE_DENSITY_THRESHOLD = 5\n",
    "ADAPTIVE_ALLOW_OVERWRITE = False\n",
    "\n",
    "# --- Graph-based Parameters ---\n",
    "GRAPH_SCALES = [75, 200, 750]\n",
    "GRAPH_ALLOW_OVERWRITE = False\n",
    "\n",
    "# --- Hybrid Parameters (SLIC + Graph combined) ---\n",
    "# Each round: {'type': 'superpixel' or 'graph', 'value': number}\n",
    "# S = superpixel count (higher = smaller regions)\n",
    "# G = graph merge threshold (higher = larger regions)\n",
    "HYBRID_ROUND_CONFIGS = [\n",
    "    {'type': 'graph', 'value': 100},       # Round 1: G:100\n",
    "    {'type': 'superpixel', 'value': 100},  # Round 2: S:100\n",
    "    {'type': 'graph', 'value': 1000}       # Round 3: G:1000\n",
    "]\n",
    "HYBRID_ALLOW_OVERWRITE = False\n",
    "\n",
    "# --- Graph-First Parameters (Anchor + Fill) ---\n",
    "# Discovery: Felzenszwalb at high scale to find obvious objects as anchors\n",
    "# Fill-in: progressive rounds of superpixel or graph to fill remaining areas\n",
    "GF_DISCOVERY_SCALE = 1000           # Felzenszwalb scale for discovery phase\n",
    "GF_FILL_METHOD = 'superpixel'      # 'superpixel' or 'graph' for fill-in rounds\n",
    "GF_FILL_VALUES = [3000, 900, 30]   # Values for each fill-in round\n",
    "GF_ALLOW_OVERWRITE = False          # Allow fill rounds to overwrite anchor labels\n",
    "\n",
    "# --- Region Merging (graph / hybrid / graph_first only) ---\n",
    "# Postprocesses the labeled mask to merge tiny Felzenszwalb fragments into\n",
    "# coherent object-level regions before COCO export.\n",
    "MERGE_ENABLED = True                # Enable/disable merge postprocessing\n",
    "MERGE_MIN_AREA = 500                # Remove speckle regions smaller than this (px)\n",
    "MERGE_SMALL_REGION = 2000            # Merge same-class regions smaller than this into neighbors\n",
    "MERGE_COLOR_THRESHOLD = 20.0        # Max RGB distance to merge adjacent same-class regions (0=off)\n",
    "MERGE_MORPH_KSIZE = 50               # Morphological closing kernel size (0=off)\n",
    "\n",
    "# --- Confidence Filtering ---\n",
    "# Set CONFIDENCE_ENABLED to False to skip confidence filtering entirely (faster)\n",
    "# Set to True to filter out uncertain segments (slower but cleaner results)\n",
    "CONFIDENCE_ENABLED = False\n",
    "CONFIDENCE_THRESHOLD = 40  # 0-100: only used when CONFIDENCE_ENABLED = True\n",
    "\n",
    "# --- Image Quality Filtering ---\n",
    "# Only process images with enough well-distributed annotations\n",
    "MIN_ANNOTATIONS = 90  # Minimum number of annotations per image\n",
    "REQUIRE_SPREAD = True  # Require annotations in all 8 squares of the image\n",
    "\n",
    "# --- Performance (Adaptive) ---\n",
    "# Workers and batch size auto-tune to use ~80% of your system (20% headroom)\n",
    "# Set TARGET_USAGE to control how aggressively it uses resources (0.0 - 1.0)\n",
    "TARGET_USAGE = 0.80       # Target 80% CPU/RAM (20% free for other tasks)\n",
    "SAVE_EVERY_N_BATCHES = 5  # Save COCO file every N batches (less disk I/O)\n",
    "\n",
    "print('Configuration loaded!')\n",
    "print(f'  Method: {SEGMENTATION_METHOD}')\n",
    "print(f'  Scale: {SCALE_FACTOR} ({SCALE_FACTOR*100:.0f}%)')\n",
    "print(f'  Region merging: {\"ON\" if MERGE_ENABLED else \"OFF\"}')\n",
    "print(f'  Confidence filtering: {\"ON (threshold: \" + str(CONFIDENCE_THRESHOLD) + \")\" if CONFIDENCE_ENABLED else \"OFF\"}')\n",
    "print(f'  Min annotations: {MIN_ANNOTATIONS}')\n",
    "print(f'  Require spread: {REQUIRE_SPREAD}')\n",
    "print(f'  Recursive: {RECURSIVE_SEARCH}')\n",
    "print(f'  Target usage: {TARGET_USAGE*100:.0f}% (adaptive workers)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO    | ============================================================\n",
      "INFO    | BATCH COCO EXPORT\n",
      "INFO    | ============================================================\n",
      "INFO    | Method: graph | Scale: 0.2\n",
      "INFO    | Region merging: ON\n",
      "INFO    | Confidence filtering: OFF\n",
      "INFO    | Output: output/test7.json\n",
      "INFO    | Log file: output\\logs\\test7_log_20260211_163351.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modules loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load modules\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import (load_labelset, load_annotations, load_image_files, \n",
    "                   find_image_path, scale_image_and_points, rescale_mask, normalize_image_name)\n",
    "from superpixel_labeling import multi_scale_labeling\n",
    "from adaptive_segmentation import multi_scale_adaptive_labeling\n",
    "from graph_segmentation import multi_scale_graph_labeling\n",
    "from hybrid_segmentation import multi_scale_hybrid_labeling\n",
    "from graph_first_segmentation import multi_scale_graph_first_labeling\n",
    "from confidence_scoring import calculate_region_confidence, apply_confidence_threshold\n",
    "from coco_export import process_single_image_to_coco\n",
    "from region_merging import merge_regions\n",
    "\n",
    "# Normalize PATH_OUTPUT: if it's a directory or has no .json extension, append default filename\n",
    "if os.path.isdir(PATH_OUTPUT) or not PATH_OUTPUT.endswith('.json'):\n",
    "    out_dir = PATH_OUTPUT.rstrip('/\\\\')\n",
    "    PATH_OUTPUT = os.path.join(out_dir, 'coco_annotations.json')\n",
    "    print(f'PATH_OUTPUT normalized to: {PATH_OUTPUT}')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(os.path.dirname(PATH_OUTPUT), exist_ok=True)\n",
    "\n",
    "# Setup logging -- logs go to output/logs/ subfolder\n",
    "LOG_DIR = os.path.join(os.path.dirname(PATH_OUTPUT), 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "log_basename = os.path.basename(PATH_OUTPUT).replace('.json', f'_log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt')\n",
    "LOG_FILE = os.path.join(LOG_DIR, log_basename)\n",
    "\n",
    "# Create logger\n",
    "logger = logging.getLogger('batch_coco')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers = []  # Clear any existing handlers\n",
    "\n",
    "# File handler - all logs go to file\n",
    "fh = logging.FileHandler(LOG_FILE)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(logging.Formatter('%(asctime)s | %(levelname)-7s | %(message)s'))\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# Console handler - INFO and above to console\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(logging.Formatter('%(levelname)-7s | %(message)s'))\n",
    "logger.addHandler(ch)\n",
    "\n",
    "logger.info('=' * 60)\n",
    "logger.info('BATCH COCO EXPORT')\n",
    "logger.info('=' * 60)\n",
    "logger.info(f'Method: {SEGMENTATION_METHOD} | Scale: {SCALE_FACTOR}')\n",
    "logger.info(f'Region merging: {\"ON\" if MERGE_ENABLED else \"OFF\"}')\n",
    "logger.info(f'Confidence filtering: {\"ON (threshold: \" + str(CONFIDENCE_THRESHOLD) + \")\" if CONFIDENCE_ENABLED else \"OFF\"}')\n",
    "logger.info(f'Output: {PATH_OUTPUT}')\n",
    "logger.info(f'Log file: {LOG_FILE}')\n",
    "print('\\nModules loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO    | Loaded 94 label classes\n",
      "INFO    | Loaded 328,578 annotations for 4689 images\n",
      "INFO    | Found 12 images in folder\n",
      "INFO    | 12 images matched with annotations\n",
      "INFO    | Quality filtering: 12 images passed\n",
      "INFO    |   Filtered out: 0 low annotation count, 0 poor spread\n",
      "INFO    | Name normalization applied to 12 images\n",
      "INFO    | Will process 12 new images (skipping 0 done)\n",
      "WARNING | 4677 annotated images not found in folder\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "labelset = load_labelset(PATH_LABELSET)\n",
    "logger.info(f'Loaded {len(labelset)} label classes')\n",
    "\n",
    "points_dict = load_annotations(PATH_ANNOTATIONS)\n",
    "total_annotations = sum(len(df) for df in points_dict.values())\n",
    "logger.info(f'Loaded {total_annotations:,} annotations for {len(points_dict)} images')\n",
    "\n",
    "image_files = load_image_files(PATH_IMAGES, recursive=RECURSIVE_SEARCH)\n",
    "logger.info(f'Found {len(image_files)} images in folder')\n",
    "\n",
    "# Match images to annotations (handles double extensions like .jpeg.jpeg)\n",
    "def get_annotation_key(image_name):\n",
    "    if image_name in points_dict:\n",
    "        return image_name\n",
    "    normalized = normalize_image_name(image_name)\n",
    "    if normalized in points_dict:\n",
    "        return normalized\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_annotation_spread(points_df, n_squares=8):\n",
    "    \"\"\"\n",
    "    Check if annotations are spread across all squares of the image.\n",
    "    Splits image into n_squares (2 rows x 4 cols for 8 squares).\n",
    "    Returns True if at least 1 annotation is in each square.\n",
    "    \"\"\"\n",
    "    if len(points_df) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Get image bounds from annotations\n",
    "    min_col, max_col = points_df['Column'].min(), points_df['Column'].max()\n",
    "    min_row, max_row = points_df['Row'].min(), points_df['Row'].max()\n",
    "    \n",
    "    # Expand bounds slightly to avoid edge issues\n",
    "    width = max_col - min_col + 1\n",
    "    height = max_row - min_row + 1\n",
    "    \n",
    "    # Split into 2 rows x 4 cols = 8 squares\n",
    "    n_cols = 4\n",
    "    n_rows = 2\n",
    "    col_step = width / n_cols\n",
    "    row_step = height / n_rows\n",
    "    \n",
    "    # Check each square has at least one annotation\n",
    "    squares_filled = set()\n",
    "    for _, row in points_df.iterrows():\n",
    "        col_idx = min(int((row['Column'] - min_col) / col_step), n_cols - 1)\n",
    "        row_idx = min(int((row['Row'] - min_row) / row_step), n_rows - 1)\n",
    "        squares_filled.add((row_idx, col_idx))\n",
    "    \n",
    "    return len(squares_filled) >= n_squares\n",
    "\n",
    "\n",
    "def filter_by_quality(image_name, annotation_key, min_annotations, require_spread):\n",
    "    \"\"\"Filter images by annotation count and spread.\"\"\"\n",
    "    points_df = points_dict[annotation_key]\n",
    "    \n",
    "    # Check minimum annotations\n",
    "    if len(points_df) < min_annotations:\n",
    "        return False, f'Only {len(points_df)} annotations (need {min_annotations})'\n",
    "    \n",
    "    # Check spread\n",
    "    if require_spread and not check_annotation_spread(points_df):\n",
    "        return False, 'Annotations not spread across all 8 squares'\n",
    "    \n",
    "    return True, None\n",
    "\n",
    "\n",
    "# First match images to annotations\n",
    "images_with_annotations = [(f, get_annotation_key(f)) for f in image_files]\n",
    "images_with_annotations = [(f, key) for f, key in images_with_annotations if key is not None]\n",
    "logger.info(f'{len(images_with_annotations)} images matched with annotations')\n",
    "\n",
    "# Apply quality filtering\n",
    "quality_filtered = []\n",
    "filtered_out = {'low_count': 0, 'poor_spread': 0}\n",
    "for img, key in images_with_annotations:\n",
    "    passed, reason = filter_by_quality(img, key, MIN_ANNOTATIONS, REQUIRE_SPREAD)\n",
    "    if passed:\n",
    "        quality_filtered.append((img, key))\n",
    "    else:\n",
    "        if 'annotations' in reason:\n",
    "            filtered_out['low_count'] += 1\n",
    "        else:\n",
    "            filtered_out['poor_spread'] += 1\n",
    "\n",
    "logger.info(f'Quality filtering: {len(quality_filtered)} images passed')\n",
    "logger.info(f'  Filtered out: {filtered_out[\"low_count\"]} low annotation count, {filtered_out[\"poor_spread\"]} poor spread')\n",
    "\n",
    "images_with_annotations = quality_filtered\n",
    "\n",
    "# Log normalization examples\n",
    "normalized_matches = [(f, key) for f, key in images_with_annotations if f != key]\n",
    "if normalized_matches:\n",
    "    logger.info(f'Name normalization applied to {len(normalized_matches)} images')\n",
    "    for img, key in normalized_matches[:3]:\n",
    "        logger.debug(f'  {img} -> {key}')\n",
    "\n",
    "# Check for existing COCO file (resume support)\n",
    "already_processed = set()\n",
    "existing_coco = None\n",
    "if os.path.exists(PATH_OUTPUT):\n",
    "    with open(PATH_OUTPUT, 'r') as f:\n",
    "        existing_coco = json.load(f)\n",
    "    already_processed = {img['file_name'] for img in existing_coco.get('images', [])}\n",
    "    logger.info(f'RESUME: Found existing COCO with {len(already_processed)} images')\n",
    "\n",
    "# Filter out already processed\n",
    "images_to_process = [(f, key) for f, key in images_with_annotations if f not in already_processed]\n",
    "logger.info(f'Will process {len(images_to_process)} new images (skipping {len(already_processed)} done)')\n",
    "\n",
    "# Check for missing images - count unique annotation image names that weren't matched\n",
    "matched_annotation_keys = {key for _, key in images_with_annotations}\n",
    "total_unique_annotation_images = len(set(points_dict.keys()))\n",
    "missing_count = total_unique_annotation_images - len(matched_annotation_keys)\n",
    "if missing_count > 0:\n",
    "    logger.warning(f'{missing_count} annotated images not found in folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define functions\n",
    "def process_single_image(image_name, annotation_key, image_id):\n",
    "    \"\"\"Process one image: sparse -> dense segmentation -> COCO annotations.\"\"\"\n",
    "    try:\n",
    "        image_path = find_image_path(PATH_IMAGES, image_name)\n",
    "        if image_path is None:\n",
    "            logger.warning(f'NOT FOUND: {image_name}')\n",
    "            return None\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            logger.warning(f'READ FAILED: {image_name}')\n",
    "            return None\n",
    "        \n",
    "        orig_h, orig_w = image.shape[:2]\n",
    "        points = points_dict[annotation_key]\n",
    "        n_input_points = len(points)\n",
    "        scaled_image, scaled_points = scale_image_and_points(image, points, SCALE_FACTOR)\n",
    "        \n",
    "        # Free original image memory immediately\n",
    "        del image\n",
    "        \n",
    "        if SEGMENTATION_METHOD == 'superpixel':\n",
    "            dense_mask, _ = multi_scale_labeling(scaled_image, scaled_points, labelset, SUPERPIXEL_SCALES)\n",
    "        elif SEGMENTATION_METHOD == 'adaptive':\n",
    "            dense_mask, _ = multi_scale_adaptive_labeling(scaled_image, scaled_points, labelset, ADAPTIVE_SCALES,\n",
    "                min_distance=ADAPTIVE_MIN_DISTANCE, density_threshold=ADAPTIVE_DENSITY_THRESHOLD, allow_overwrite=ADAPTIVE_ALLOW_OVERWRITE)\n",
    "        elif SEGMENTATION_METHOD == 'graph':\n",
    "            dense_mask, _ = multi_scale_graph_labeling(scaled_image, scaled_points, labelset, GRAPH_SCALES, allow_overwrite=GRAPH_ALLOW_OVERWRITE)\n",
    "        elif SEGMENTATION_METHOD == 'hybrid':\n",
    "            dense_mask, _ = multi_scale_hybrid_labeling(scaled_image, scaled_points, labelset, HYBRID_ROUND_CONFIGS, allow_overwrite=HYBRID_ALLOW_OVERWRITE)\n",
    "        elif SEGMENTATION_METHOD == 'graph_first':\n",
    "            dense_mask, _ = multi_scale_graph_first_labeling(scaled_image, scaled_points, labelset,\n",
    "                discovery_scale=GF_DISCOVERY_SCALE, fill_method=GF_FILL_METHOD,\n",
    "                fill_values=GF_FILL_VALUES, allow_overwrite=GF_ALLOW_OVERWRITE)\n",
    "        else:\n",
    "            logger.error(f'Unknown method: {SEGMENTATION_METHOD}')\n",
    "            return None\n",
    "        \n",
    "        # Region merging: collapse Felzenszwalb fragments into object-level masks\n",
    "        if MERGE_ENABLED and SEGMENTATION_METHOD in ('graph', 'hybrid', 'graph_first'):\n",
    "            n_before = len(np.unique(dense_mask)) - 1  # exclude bg\n",
    "            dense_mask = merge_regions(\n",
    "                dense_mask,\n",
    "                image=scaled_image if MERGE_COLOR_THRESHOLD > 0 else None,\n",
    "                min_area=MERGE_MIN_AREA,\n",
    "                small_region_merge=MERGE_SMALL_REGION,\n",
    "                color_threshold=MERGE_COLOR_THRESHOLD,\n",
    "                morph_close_ksize=MERGE_MORPH_KSIZE,\n",
    "            )\n",
    "            n_after = len(np.unique(dense_mask)) - 1\n",
    "            logger.debug(f'MERGE {image_name}: classes {n_before} -> {n_after}')\n",
    "        \n",
    "        del scaled_image\n",
    "        \n",
    "        # Apply confidence filtering only if enabled\n",
    "        if CONFIDENCE_ENABLED and CONFIDENCE_THRESHOLD > 0:\n",
    "            confidence_map, _ = calculate_region_confidence(dense_mask, scaled_points, labelset)\n",
    "            dense_mask = apply_confidence_threshold(dense_mask, confidence_map, CONFIDENCE_THRESHOLD)\n",
    "        \n",
    "        if dense_mask.sum() == 0:\n",
    "            logger.warning(f'EMPTY MASK: {image_name}')\n",
    "            return None\n",
    "        \n",
    "        # Export COCO: segmentation at scaled res, coords rescaled to original dims\n",
    "        scaled_h, scaled_w = dense_mask.shape[:2]\n",
    "        image_entry, annotations = process_single_image_to_coco(\n",
    "            (image_id, image_name, dense_mask, orig_w, orig_h, SCALE_FACTOR))\n",
    "        \n",
    "        n_out = len(annotations)\n",
    "        logger.debug(\n",
    "            f'OK: {image_name} ({orig_w}x{orig_h} -> {scaled_w}x{scaled_h}) | '\n",
    "            f'{n_input_points} pts in -> {n_out} regions out'\n",
    "        )\n",
    "        return {\n",
    "            'image_entry': image_entry,\n",
    "            'annotations': annotations,\n",
    "            'orig_w': orig_w,\n",
    "            'orig_h': orig_h,\n",
    "            'n_input_points': n_input_points,\n",
    "            'name': image_name\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f'ERROR: {image_name}: {e}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_coco(coco_data, output_path):\n",
    "    \"\"\"Save COCO dict to JSON file with readable formatting.\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_data, f, indent=2)\n",
    "    logger.info(f'SAVED: {len(coco_data[\"images\"])} images, {len(coco_data[\"annotations\"])} annotations')\n",
    "\n",
    "print('Functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO    | SAVED: 0 images, 0 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO    | Starting processing of 12 images...\n",
      "INFO    | System: 16 CPU cores | 31.7 GB RAM\n",
      "INFO    | Adaptive: target 80% usage | workers 2-12 | start 6\n",
      "Total: 100%|██████████| 12/12 [00:29<00:00,  2.45s/img, 6w | CPU:53% RAM:74% | 2.4s/img | ETA:0.0m]\n",
      "INFO    | ============================================================\n",
      "INFO    | PROCESSING COMPLETE\n",
      "INFO    | ============================================================\n",
      "INFO    | Total time: 30.6s (0.5 min)\n",
      "INFO    | Processed: 12 images | Failed: 0\n",
      "INFO    | Final workers: 6 (range was 2-12)\n",
      "INFO    | Speed: 2.55s per image\n"
     ]
    }
   ],
   "source": [
    "# Process images\n",
    "import psutil\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Build initial COCO structure\n",
    "if existing_coco is not None:\n",
    "    coco_data = existing_coco\n",
    "    next_image_id = max((img['id'] for img in coco_data['images']), default=0) + 1\n",
    "    next_ann_id = max((ann['id'] for ann in coco_data['annotations']), default=0) + 1\n",
    "else:\n",
    "    coco_data = {\n",
    "        'images': [],\n",
    "        'annotations': [],\n",
    "        'categories': [\n",
    "            {'id': int(entry['Count']), 'name': entry['Short Code']} for entry in labelset\n",
    "        ]\n",
    "    }\n",
    "    next_image_id = 1\n",
    "    next_ann_id = 1\n",
    "\n",
    "# Save empty COCO file right away\n",
    "save_coco(coco_data, PATH_OUTPUT)\n",
    "\n",
    "# ---- Adaptive resource manager ----\n",
    "cpu_count = psutil.cpu_count()\n",
    "ram_total_gb = psutil.virtual_memory().total / 1024**3\n",
    "max_workers_limit = max(2, int(cpu_count * TARGET_USAGE))\n",
    "min_workers = 2\n",
    "\n",
    "# Start conservative: half of limit, ramps up quickly if headroom exists\n",
    "current_workers = max(min_workers, max_workers_limit // 2)\n",
    "\n",
    "active_workers = 0\n",
    "active_workers_lock = threading.Lock()\n",
    "peak_workers = 0\n",
    "\n",
    "def get_system_load():\n",
    "    \"\"\"Sample CPU and RAM usage.\"\"\"\n",
    "    cpu = psutil.cpu_percent(interval=0.3, percpu=False)\n",
    "    ram = psutil.virtual_memory().percent\n",
    "    return cpu, ram\n",
    "\n",
    "def adapt_workers(current, cpu_pct, ram_pct):\n",
    "    \"\"\"Adjust worker count based on system load.\"\"\"\n",
    "    target = TARGET_USAGE * 100\n",
    "    ceiling = target + 5\n",
    "    floor = target - 20\n",
    "    \n",
    "    new = current\n",
    "    if cpu_pct > ceiling or ram_pct > ceiling:\n",
    "        new = max(min_workers, current - 2)\n",
    "    elif cpu_pct > target or ram_pct > target:\n",
    "        new = max(min_workers, current - 1)\n",
    "    elif cpu_pct < floor and ram_pct < floor:\n",
    "        new = min(max_workers_limit, current + 2)\n",
    "    elif cpu_pct < target - 10 and ram_pct < target - 10:\n",
    "        new = min(max_workers_limit, current + 1)\n",
    "    return new\n",
    "\n",
    "def process_single_image_tracked(image_name, annotation_key, image_id):\n",
    "    \"\"\"Wrapper that tracks active worker count.\"\"\"\n",
    "    global active_workers, peak_workers\n",
    "    with active_workers_lock:\n",
    "        active_workers += 1\n",
    "        peak_workers = max(peak_workers, active_workers)\n",
    "    try:\n",
    "        return process_single_image(image_name, annotation_key, image_id)\n",
    "    finally:\n",
    "        with active_workers_lock:\n",
    "            active_workers -= 1\n",
    "\n",
    "if len(images_to_process) == 0:\n",
    "    logger.info('All images already processed!')\n",
    "    print('All images already processed!')\n",
    "else:\n",
    "    total_images = len(images_to_process)\n",
    "    \n",
    "    logger.info(f'Starting processing of {total_images} images...')\n",
    "    logger.info(f'System: {cpu_count} CPU cores | {ram_total_gb:.1f} GB RAM')\n",
    "    logger.info(f'Adaptive: target {TARGET_USAGE*100:.0f}% usage | workers {min_workers}-{max_workers_limit} | start {current_workers}')\n",
    "    \n",
    "    # Suppress console logger during processing\n",
    "    ch.setLevel(logging.WARNING)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    total_new = 0\n",
    "    total_failed = 0\n",
    "    failed = []\n",
    "    global_done = 0\n",
    "    batches_since_save = 0\n",
    "\n",
    "    # Assign image IDs upfront\n",
    "    image_id_map = {img: next_image_id + i for i, (img, _) in enumerate(images_to_process)}\n",
    "\n",
    "    # Overall progress bar\n",
    "    overall_bar = tqdm(total=total_images, desc='Total', unit='img', position=0)\n",
    "    \n",
    "    idx = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    while idx < total_images:\n",
    "        batch_size = current_workers\n",
    "        batch = images_to_process[idx:idx + batch_size]\n",
    "        batch_num += 1\n",
    "        \n",
    "        batch_start_time = datetime.now()\n",
    "        peak_workers = 0\n",
    "        batch_done = 0\n",
    "        \n",
    "        # Per-batch bar\n",
    "        batch_bar = tqdm(\n",
    "            total=len(batch),\n",
    "            desc=f'Batch {batch_num} ({current_workers}w)',\n",
    "            unit='img', position=1, leave=False\n",
    "        )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=current_workers) as executor:\n",
    "            futures = {\n",
    "                executor.submit(process_single_image_tracked, img, key, image_id_map[img]): (img, key)\n",
    "                for img, key in batch\n",
    "            }\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                img, key = futures[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    batch_done += 1\n",
    "                    global_done += 1\n",
    "                    if result:\n",
    "                        coco_data['images'].append(result['image_entry'])\n",
    "                        for ann in result['annotations']:\n",
    "                            ann['id'] = next_ann_id\n",
    "                            coco_data['annotations'].append(ann)\n",
    "                            next_ann_id += 1\n",
    "                        total_new += 1\n",
    "                    else:\n",
    "                        failed.append(img)\n",
    "                        total_failed += 1\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                    avg_time = elapsed / global_done\n",
    "                    eta_m = (total_images - global_done) * avg_time / 60\n",
    "                    cpu_now = psutil.cpu_percent(interval=0)\n",
    "                    ram_now = psutil.virtual_memory().percent\n",
    "                    overall_bar.set_postfix_str(\n",
    "                        f'{current_workers}w | CPU:{cpu_now:.0f}% RAM:{ram_now:.0f}% | '\n",
    "                        f'{avg_time:.1f}s/img | ETA:{eta_m:.1f}m'\n",
    "                    )\n",
    "                    batch_bar.update(1)\n",
    "                    overall_bar.update(1)\n",
    "                    \n",
    "                    # Log file only\n",
    "                    if result:\n",
    "                        n_in = result['n_input_points']\n",
    "                        n_out = len(result['annotations'])\n",
    "                        dims = f\"{result['orig_w']}x{result['orig_h']}\"\n",
    "                        logger.debug(f'OK {img} ({dims}) | {n_in} pts -> {n_out} regions')\n",
    "                    else:\n",
    "                        logger.debug(f'SKIP {img}')\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    batch_done += 1\n",
    "                    global_done += 1\n",
    "                    total_failed += 1\n",
    "                    logger.error(f'ERROR {img}: {e}')\n",
    "                    failed.append(img)\n",
    "                    batch_bar.update(1)\n",
    "                    overall_bar.update(1)\n",
    "        \n",
    "        batch_bar.close()\n",
    "        \n",
    "        # Adaptive: measure load and adjust workers for next batch\n",
    "        cpu_pct, ram_pct = get_system_load()\n",
    "        old_workers = current_workers\n",
    "        current_workers = adapt_workers(current_workers, cpu_pct, ram_pct)\n",
    "        \n",
    "        batch_time = (datetime.now() - batch_start_time).total_seconds()\n",
    "        if current_workers > old_workers:\n",
    "            direction = '++'\n",
    "        elif current_workers < old_workers:\n",
    "            direction = '--'\n",
    "        else:\n",
    "            direction = '=='\n",
    "        logger.info(\n",
    "            f'Batch {batch_num} ({len(batch)} imgs) {batch_time:.1f}s | '\n",
    "            f'CPU:{cpu_pct:.0f}% RAM:{ram_pct:.0f}% | '\n",
    "            f'Workers: {old_workers}{direction}{current_workers} | '\n",
    "            f'Total: {len(coco_data[\"images\"])} imgs, {len(coco_data[\"annotations\"]):,} ann'\n",
    "        )\n",
    "        \n",
    "        # Save periodically\n",
    "        batches_since_save += 1\n",
    "        if batches_since_save >= SAVE_EVERY_N_BATCHES:\n",
    "            save_coco(coco_data, PATH_OUTPUT)\n",
    "            batches_since_save = 0\n",
    "        \n",
    "        idx += len(batch)\n",
    "        gc.collect()\n",
    "\n",
    "    overall_bar.close()\n",
    "    \n",
    "    # Final save\n",
    "    save_coco(coco_data, PATH_OUTPUT)\n",
    "    \n",
    "    # Restore console logger\n",
    "    ch.setLevel(logging.INFO)\n",
    "    \n",
    "    total_time = (datetime.now() - start_time).total_seconds()\n",
    "    logger.info('=' * 60)\n",
    "    logger.info('PROCESSING COMPLETE')\n",
    "    logger.info('=' * 60)\n",
    "    logger.info(f'Total time: {total_time:.1f}s ({total_time/60:.1f} min)')\n",
    "    logger.info(f'Processed: {total_new} images | Failed: {total_failed}')\n",
    "    logger.info(f'Final workers: {current_workers} (range was {min_workers}-{max_workers_limit})')\n",
    "    if total_new > 0:\n",
    "        logger.info(f'Speed: {total_time/total_new:.2f}s per image')\n",
    "    \n",
    "    if failed:\n",
    "        logger.warning(f'Failed images: {failed[:10]}')\n",
    "        if len(failed) > 10:\n",
    "            logger.warning(f'  ... and {len(failed) - 10} more (see log file)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUN COMPLETE\n",
      "============================================================\n",
      "COCO file: output/test7.json\n",
      "  Images: 12\n",
      "  Annotations: 471\n",
      "  Categories: 94\n",
      "\n",
      "Log file: output\\logs\\test7_log_20260211_163351.txt\n",
      "\n",
      "Ready for Roboflow upload!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "if os.path.exists(PATH_OUTPUT):\n",
    "    with open(PATH_OUTPUT, 'r') as f:\n",
    "        final_coco = json.load(f)\n",
    "\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('RUN COMPLETE')\n",
    "    print('=' * 60)\n",
    "    print(f'COCO file: {PATH_OUTPUT}')\n",
    "    print(f'  Images: {len(final_coco[\"images\"])}')\n",
    "    print(f'  Annotations: {len(final_coco[\"annotations\"]):,}')\n",
    "    print(f'  Categories: {len(final_coco[\"categories\"])}')\n",
    "    print(f'\\nLog file: {LOG_FILE}')\n",
    "    print('\\nReady for Roboflow upload!')\n",
    "else:\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('NO OUTPUT FILE')\n",
    "    print('=' * 60)\n",
    "    print(f'No COCO file was created at {PATH_OUTPUT}')\n",
    "    print('This can happen if no images passed quality filtering or all masks were empty.')\n",
    "    print(f'Check the log file: {LOG_FILE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
